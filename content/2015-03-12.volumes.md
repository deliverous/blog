Title: Vous avez dit volumes ? 
Tags: docker, volume, deliverous
Authors: Thomas Clavier
Summary: Quelles sont les bonnes pratiques avec les volumes ? C'est une question récurrente que ce soit dans les conférences que nous donnons, dans les meetups ou de la part de nos clients.
Status: published

À défaut de pouvoir vous apporter une réponse unique à la questions : Quelles sont les bonnes pratiques avec les volumes ? Je propose de vous apporter quelques pistes de réflexions.


# Uploads partagés

Imaginons une application qui sauvegarde ses données utilisateurs dans un
répertoire local, disons, /uploads/ C'est le cas d'usage le plus classique,
Wordpress, Magento et bien d'autres sauvegardent certains fichiers téléversés
par les utilisateurs dans un répertoire du système de fichier. Ces fichiers
sont des données applicatives, impossible de les laisser dans le conteneur
d'autant plus si l'on doit multiplier le nombre d'instances du conteneur,
en effet, tous devront pouvoir lire et écrire dans ce vaste dossier partagé des
uploads.

## Goulot d'étranglement

Avoir un unique point d'entrée vers un service limitera forcément à un moment ou un autre les capacités de ce service. Imaginez une autoroute à 2 fois 3 voies avec pour y entrer un péage avec uniquement 2 guichets. Le point d'entrée étant très limité il n'y aura jamais beaucoup de monde. 
Aujourd'hui malgré des technologies réseau très innovantes il est difficile de dépasser certains débits ce qui à terme risquera fort de limiter les capacité de communication du système de fichier distribué.

## Théorème de CAP

Le théorème de CAP dit qu'il est impossible sur un système informatique de calcul distribué de garantir en même temps les trois contraintes suivantes :
- Cohérence : tous les nœuds du système voient exactement les mêmes données au même moment 
- Disponibilité : garantie que toutes les requêtes reçoivent une réponse;
- Résistance au morcellement : aucune panne moins importante qu'une coupure totale du réseau ne doit empêcher le système de répondre correctement

Un système de fichier distribué entre tous les conteneurs va forcément se
retrouvé confronté au théorème de CAP, en effet comment garantir la cohérence
du système avec des temps de réponse très court quand nous avons une grande
quantité de conteneur qui accèdent en même temps aux mêmes fichiers. Un système
de fichier, qu'il soit distribué ou non, est par nature cohérent, et un système
comme celui là se doit d'être résistant au morcellement. Le respect de ces
contraintes se fera forcément au détriment de la disponibilité.

## Malgré tout

Ce mode de fonctionnement pose donc 2 problèmes : 
- Un point centrale, point d'entrée du système de fichier partagé, qui va forcément ralentir voir bloquer la montée en charge. 
- Un ralentissement lié au théorème de CAP

Malgré ces défauts, pour une application ne nécessitant pas d'avoir plus d'un
conteneur applicatif, c'est une solution simple et efficace pour sauver les
données des utilisateurs.

Avec l'augmentation du nombre d'instances de conteneur, il faudra sans doute
penser à monter un conteneur qui sera dédié à la réception des uploads comme
pourrait le faire un CDN. La lecture et l'écriture sur ce conteneur se faisant
en mode déconnecté. Par exemple en ftp pour l'écriture et en http pour la
lecture.

# Des dossiers séparés

Il est aussi possible d'utiliser les volumes pour différencier sur
l'hyperviseur des données provenant de différentes instances du même conteneur.
Par exemple pour identifier les logs des instances de différents clients. 

Prenons l'exemple d'un conteneur avec une application qui log tout dans
/var/log/application/ avec les options de montage des volumes il est possible
de lancer 3 fois cette même applications et de sauver les fichiers générés dans
3 répertoires différents : 

    :::shell
    docker run -v /data/application1/logs:/var/log/application --name application1 conteneur
    docker run -v /data/application2/logs:/var/log/application --name application2 conteneur
    docker run -v /data/application3/logs:/var/log/application --name application3 conteneur

Dans ce contexte, les documents générés peuvent être écris sur le disque du
serveur et agrégés à postériori dans un autre conteneur.
Une autre solution plus robuste consisterait à monter un conteneur de
centralisation de log et à configurer le conteneur "conteneur" pour envoyer les
logs sur celui-ci.

Ce mode de fonctionnement peut aussi être utilisé pour différencier différentes
instances d'un même conteneur. Prenons l'exemple d'une application qui lit et
écrit l'ensemble de ses données applicatives dans /home/application. Il est
possible de dédier chaque instance à un usage donné. 

    :::shell
    docker run -v /data/application1:/home/application --name application1 conteneur
    docker run -v /data/application2:/home/application --name application2 conteneur

Avec cette configuration, chaque conteneur va pouvoir vivre sa vie avec ses propres données.

# SELinux

Tout ça pose des problèmes de droits ... le matching d'id utilisateurs entre le conteneur et l'hote n'est pas prévésible. 

---
Photo par [tetue](https://www.flickr.com/photos/romytetue/109188206)
